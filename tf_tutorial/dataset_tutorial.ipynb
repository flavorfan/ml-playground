{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:49:39.867312Z",
     "start_time": "2020-03-18T14:49:37.937237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T00:14:37.000389Z",
     "start_time": "2020-03-15T00:14:36.975184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n",
      "[0.86120820475770821 0.4523921465582661]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.random.sample((100,2))\n",
    "# make a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "print(type(dataset))  #<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n",
    "\n",
    "# for it in dataset:\n",
    "#     tf.print(it)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "tf.print(next_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two numpy arrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T00:15:59.691932Z",
     "start_time": "2020-03-15T00:15:59.660923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.60325773388617721 0.56485462854184276], [0.15529337848484637])\n"
     ]
    }
   ],
   "source": [
    "# using two numpy arrays\n",
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "\n",
    "iterator = iter(dataset)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "tf.print(next_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T00:17:44.087128Z",
     "start_time": "2020-03-15T00:17:44.034206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57677114 0.279497623]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# using a tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.random.uniform([100, 2]))\n",
    "iterator = iter(dataset)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "tf.print(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T00:18:55.625143Z",
     "start_time": "2020-03-15T00:18:55.558628Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5f2c9e447383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m dataset = tf.data.Dataset().batch(1).from_generator(generator,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                            \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            output_shapes=(tf.TensorShape([None, 1])))\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec"
     ]
    }
   ],
   "source": [
    "# from generator\n",
    "sequence = np.array([[[1]],[[2],[3]],[[3],[4],[5]]])\n",
    "\n",
    "def generator():\n",
    "    for el in sequence:\n",
    "        yield el\n",
    "\n",
    "dataset = tf.data.Dataset().batch(1).from_generator(generator,\n",
    "                                           output_types= tf.int64, \n",
    "                                           output_shapes=(tf.TensorShape([None, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:49:43.699220Z",
     "start_time": "2020-03-18T14:49:43.695219Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_mnist_dataset(batch_size = 64):\n",
    "    ((trainX, _), (testX, _)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # add a channel dimension to every image in the dataset, then scale\n",
    "    # the pixel intensities to the range [0, 1]\n",
    "    trainX = np.expand_dims(trainX, axis=-1)  # (sample,w,h) -> (sample, w, h, d)\n",
    "    testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "    trainX = trainX.astype(\"float32\") / 255.0\n",
    "    testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((trainX, trainX))\n",
    "    train_data = train_data.shuffle(5000).batch(batch_size)\n",
    "\n",
    "    test_data = tf.data.Dataset.from_tensor_slices((testX, testX))\n",
    "    test_data = test_data.shuffle(5000).batch(batch_size)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:49:45.040520Z",
     "start_time": "2020-03-18T14:49:44.156322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:50:07.383093Z",
     "start_time": "2020-03-18T14:50:07.380092Z"
    }
   },
   "outputs": [],
   "source": [
    "testX = test_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:58:48.055019Z",
     "start_time": "2020-03-18T14:58:48.044017Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TakeDataset' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-32a111665037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TakeDataset' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "testX.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
