{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCQY7jpBfMur"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "z6X9omPnfO_h"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1xIRPtY0E1w"
   },
   "source": [
    "# Keras overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyOjQZHhZxaA"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUJTep_x5-R8"
   },
   "source": [
    "This guide gives you the basics to get started with Keras. It's a 10-minute read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsK5aF2xZ-40"
   },
   "source": [
    "## Import tf.keras\n",
    "\n",
    "`tf.keras` is TensorFlow's implementation of the\n",
    "[Keras API specification](https://keras.io). This is a high-level\n",
    "API to build and train models that includes first-class support for\n",
    "TensorFlow-specific functionality, such as [eager execution](../eager.ipynb),\n",
    "`tf.data` pipelines, and [Estimators](../estimator.ipynb).\n",
    "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
    "performance.\n",
    "\n",
    "To get started, import `tf.keras` as part of your TensorFlow program setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T00:49:55.250162Z",
     "start_time": "2020-03-17T00:49:53.096391Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TgPcBFru0E1z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T00:45:21.501458Z",
     "start_time": "2020-03-17T00:42:20.708942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /pylib/package/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 18kB/s eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.0)\n",
      "Collecting six>=1.12.0 (from tensorflow==2.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.7)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.23.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.9.1)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 75kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow==2.1.0) (0.30.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (41.2.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/f8/2da482a6165ef3f28d52faf8c2ca31628129a84a294033eb399ef500e265/google_auth-1.11.3-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 104kB/s ta 0:00:0111\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.15.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.22.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 63kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.9.11)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 34kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 17kB/s eta 0:00:01\n",
      "\u001b[31mERROR: tensorboard 2.1.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow-estimator, six, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed cachetools-4.0.0 google-auth-1.11.3 google-auth-oauthlib-0.4.1 oauthlib-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 six-1.14.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install /pylib/package/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
    "# !pip install /pylib/package/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lj03RamP0E13"
   },
   "source": [
    "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
    "\n",
    "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
    "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
    "* When [saving a model's weights](./save_and_serialize.ipynb), `tf.keras` defaults to the\n",
    "  [checkpoint format](../checkpoint.ipynb). Pass `save_format='h5'` to\n",
    "  use HDF5 (or pass a filename that ends in `.h5`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e1LPcXx0gR6"
   },
   "source": [
    "## Build a simple model\n",
    "\n",
    "### Sequential model\n",
    "\n",
    "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
    "of layers. The most common type of model is a stack of layers: the\n",
    "`tf.keras.Sequential` model.\n",
    "\n",
    "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:32:29.964543Z",
     "start_time": "2020-03-16T13:32:29.930528Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WM-DUVQB0E14"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add an output layer with 10 output units:\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2oH0-cxH7YA"
   },
   "source": [
    "You can find a complete, short example of how to use Sequential models [here](https://www.tensorflow.org/tutorials/quickstart/beginner).\n",
    "\n",
    "To learn about building more advanced models than Sequential models, see:\n",
    "- [Guide to the Keras Functional API](./functional.ipynb)\n",
    "- [Guide to writing layers and models from scratch with subclassing](./custom_layers_and_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ztyTipu0E18"
   },
   "source": [
    "### Configure the layers\n",
    "\n",
    "There are many `tf.keras.layers` available. Most of them share some common constructor\n",
    "arguments:\n",
    "\n",
    "* `activation`: Set the activation function for the layer. This parameter is\n",
    "  specified by the name of a built-in function or as a callable object. By\n",
    "  default, no activation is applied.\n",
    "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
    "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
    "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
    "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
    "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
    "  regularization. By default, no regularization is applied.\n",
    "\n",
    "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
    "arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:32:48.289653Z",
     "start_time": "2020-03-16T13:32:48.276651Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MlL7PBtp0E19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1e63b1ced68>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a relu layer:\n",
    "layers.Dense(64, activation='relu')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.nn.relu)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NR6reyk0E2A"
   },
   "source": [
    "## Train and evaluate\n",
    "\n",
    "### Set up training\n",
    "\n",
    "After the model is constructed, configure its learning process by calling the\n",
    "`compile` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:32:51.941472Z",
     "start_time": "2020-03-16T13:32:50.983258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sJ4AOn090E2A"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add an output layer with 10 output units:\n",
    "layers.Dense(10)])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HG-RAa9F0E2D"
   },
   "source": [
    "`tf.keras.Model.compile` takes three important arguments:\n",
    "\n",
    "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
    "  instances from the `tf.keras.optimizers` module, such as\n",
    "  `tf.keras.optimizers.Adam` or\n",
    "  `tf.keras.optimizers.SGD`. If you just want to use the default parameters, you can also specify optimizers via strings, such as `'adam'` or `'sgd'`.\n",
    "* `loss`: The function to minimize during optimization. Common choices include\n",
    "  mean square error (`mse`), `categorical_crossentropy`, and\n",
    "  `binary_crossentropy`. Loss functions are specified by name or by\n",
    "  passing a callable object from the `tf.keras.losses` module.\n",
    "* `metrics`: Used to monitor training. These are string names or callables from\n",
    "  the `tf.keras.metrics` module.\n",
    "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass `run_eagerly=True` as a parameter to compile.\n",
    "\n",
    "\n",
    "The following shows a few examples of configuring a model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:32:54.855126Z",
     "start_time": "2020-03-16T13:32:54.820118Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "St4Mgdar0E2E"
   },
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjI5rbi80E2G"
   },
   "source": [
    "### Train from NumPy data\n",
    "\n",
    "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
    "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
    "using the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:32:58.228874Z",
     "start_time": "2020-03-16T13:32:56.992605Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3CvP6L-m0E2I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 271.0570 - accuracy: 0.1010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1007.8014 - accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 2099.7821 - accuracy: 0.1210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 3547.7503 - accuracy: 0.1030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 5127.8301 - accuracy: 0.1210\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 7147.8054 - accuracy: 0.1190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 9262.4652 - accuracy: 0.1080\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 12705.9606 - accuracy: 0.1090\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 14925.1500 - accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 18272.8729 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e63b36b278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-pnVaFe0E2N"
   },
   "source": [
    "`tf.keras.Model.fit` takes three important arguments:\n",
    "\n",
    "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
    "  the entire input data (this is done in smaller batches).\n",
    "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
    "  batches and iterates over these batches during training. This integer\n",
    "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
    "  if the total number of samples is not divisible by the batch size.\n",
    "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
    "  performance on some validation data. Passing this argument—a tuple of inputs\n",
    "  and labels—allows the model to display the loss and metrics in inference mode\n",
    "  for the passed data, at the end of each epoch.\n",
    "\n",
    "Here's an example using `validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:03.611081Z",
     "start_time": "2020-03-16T13:33:02.717880Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gFcXzVQa0E2N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 22078.6553 - accuracy: 0.0980 - val_loss: 27506.8531 - val_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 25647.3229 - accuracy: 0.1090 - val_loss: 35224.2213 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 29332.1169 - accuracy: 0.1240 - val_loss: 30001.3478 - val_accuracy: 0.0900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 34207.7596 - accuracy: 0.1000 - val_loss: 24597.3301 - val_accuracy: 0.1200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 37467.3553 - accuracy: 0.1270 - val_loss: 39164.5706 - val_accuracy: 0.1500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 45115.8512 - accuracy: 0.0990 - val_loss: 77005.3628 - val_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 51360.3996 - accuracy: 0.0990 - val_loss: 55834.9741 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 53973.4721 - accuracy: 0.1090 - val_loss: 54675.9256 - val_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 62134.6964 - accuracy: 0.0880 - val_loss: 50258.8289 - val_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 67563.8926 - accuracy: 0.0870 - val_loss: 66913.4775 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6418ee240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6ImyXzz0E2Q"
   },
   "source": [
    "### Train from tf.data datasets\n",
    "\n",
    "Use the [Datasets API](../data.ipynb) to scale to large datasets\n",
    "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:08.126093Z",
     "start_time": "2020-03-16T13:33:07.242904Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OziqhpIj0E2R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32 steps\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 72513.9356 - accuracy: 0.1020\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 80596.1448 - accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 85714.3306 - accuracy: 0.1060\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 93913.6091 - accuracy: 0.1020\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 102310.7920 - accuracy: 0.0930\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 110839.8017 - accuracy: 0.0930\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 116543.1516 - accuracy: 0.1090\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 128592.2166 - accuracy: 0.0970\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 133996.5096 - accuracy: 0.1160\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 146439.7993 - accuracy: 0.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6348db860>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7BcMHkB0E2U"
   },
   "source": [
    "Since the `Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
    "\n",
    "Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:12.032970Z",
     "start_time": "2020-03-16T13:33:11.128776Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YPMb3A0N0E2V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32 steps, validate for 4 steps\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 156311.9951 - accuracy: 0.1110 - val_loss: 182035.3438 - val_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 162303.9549 - accuracy: 0.0980 - val_loss: 140271.9355 - val_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 174583.6203 - accuracy: 0.1000 - val_loss: 169843.4453 - val_accuracy: 0.0900\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 180723.8969 - accuracy: 0.1190 - val_loss: 170333.5430 - val_accuracy: 0.0800\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 193506.5706 - accuracy: 0.1030 - val_loss: 191996.9297 - val_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 207813.1912 - accuracy: 0.0970 - val_loss: 220734.3359 - val_accuracy: 0.0800\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 213834.2232 - accuracy: 0.1060 - val_loss: 279142.1016 - val_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 221832.7122 - accuracy: 0.0880 - val_loss: 222759.2383 - val_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 242962.2403 - accuracy: 0.0900 - val_loss: 268176.0430 - val_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 253146.2909 - accuracy: 0.1020 - val_loss: 329914.2109 - val_accuracy: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e64193c940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgGdlXso0E2X"
   },
   "source": [
    "### Evaluate and predict\n",
    "\n",
    "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
    "data and a `tf.data.Dataset`.\n",
    "\n",
    "Here's how to *evaluate* the inference-mode loss and metrics for the data provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:14.632553Z",
     "start_time": "2020-03-16T13:33:14.500533Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mhDbOHEK0E2Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 45us/sample - loss: 313966.5658 - accuracy: 0.1050\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 313460.8994 - accuracy: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[313460.8994140625, 0.105]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Numpy arrays\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "# With a Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXUTmDfb0E2b"
   },
   "source": [
    "And here's how to *predict* the output of the last layer in inference for the data provided,\n",
    "as a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:17.728247Z",
     "start_time": "2020-03-16T13:33:17.675243Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9e3JsSoQ0E2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuTb71gYILLG"
   },
   "source": [
    "For a complete guide on training and evaluation, including how to write custom training loops from scratch, see the [guide to training and evaluation](./train_and_evaluate.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzEOW4Cn0E2h"
   },
   "source": [
    "## Build complex models\n",
    "\n",
    "### The Functional API\n",
    "\n",
    " The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
    "represent arbitrary models. Use the\n",
    "[Keras functional API](./functional.ipynb)\n",
    "to build complex model topologies such as:\n",
    "\n",
    "* Multi-input models,\n",
    "* Multi-output models,\n",
    "* Models with shared layers (the same layer called several times),\n",
    "* Models with non-sequential data flows (e.g. residual connections).\n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
    "   instance.\n",
    "3. This model is trained just like the `Sequential` model.\n",
    "\n",
    "The following example uses the functional API to build a simple, fully-connected\n",
    "network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:33:34.405987Z",
     "start_time": "2020-03-16T13:33:34.385982Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mROj832r0E2i"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns an input placeholder\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFmspHeG1_W7"
   },
   "source": [
    "Instantiate the model given inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5k5uzlyu16HM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 439us/sample - loss: 13.6052 - accuracy: 0.1060\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 23.8268 - accuracy: 0.1180\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 39.7324 - accuracy: 0.1090\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 59.5228 - accuracy: 0.1080\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 76.4868 - accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf143cb080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcKSLH3i0E2k"
   },
   "source": [
    "### Model subclassing\n",
    "\n",
    "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
    "your own forward pass. Create layers in the `__init__` method and set them as\n",
    "attributes of the class instance. Define the forward pass in the `call` method.\n",
    "\n",
    "Model subclassing is particularly useful when\n",
    "[eager execution](../eager.ipynb) is enabled, because it allows the forward pass\n",
    "to be written imperatively.\n",
    "\n",
    "Note: if you need your model to *always* run imperatively, you can set `dynamic=True` when calling the `super` constructor.\n",
    "\n",
    "> Key Point: Use the right API for the job. While model subclassing offers\n",
    "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
    "user errors. If possible, prefer the functional API.\n",
    "\n",
    "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
    "pass that does not have to be run imperatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:34:49.621416Z",
     "start_time": "2020-03-16T13:34:49.617416Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KLiHWzcn2Fzk"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    self.num_classes = num_classes\n",
    "    # Define your layers here.\n",
    "    self.dense_1 = layers.Dense(32, activation='relu')\n",
    "    self.dense_2 = layers.Dense(num_classes)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    x = self.dense_1(inputs)\n",
    "    return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShDD4fv72KGc"
   },
   "source": [
    "Instantiate the new model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:35:01.518076Z",
     "start_time": "2020-03-16T13:35:00.912949Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "42C-qQHm0E2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 259us/sample - loss: 11.9413 - accuracy: 0.1070\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 13.0159 - accuracy: 0.1020\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 14.5126 - accuracy: 0.1030\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 16.2859 - accuracy: 0.1070\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 18.4954 - accuracy: 0.1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e89afa2a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqRQiKj20E2o"
   },
   "source": [
    "### Custom layers\n",
    "\n",
    "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
    "the following methods:\n",
    "\n",
    "* `__init__`: Optionally define sublayers to be used by this layer.\n",
    "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
    "  method.\n",
    "* `call`: Define the forward pass.\n",
    "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
    "  and the `from_config` class method.\n",
    "\n",
    "Here's an example of a custom layer that implements a `matmul` of an input with\n",
    "a kernel matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:35:04.382719Z",
     "start_time": "2020-03-16T13:35:04.377726Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l7BFnIHr2WNc"
   },
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=(input_shape[1], self.output_dim),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "    return base_config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wXDRgXV2ZrF"
   },
   "source": [
    "Create a model using your custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:35:11.139234Z",
     "start_time": "2020-03-16T13:35:10.679139Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uqH-cY0h0E2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 160us/sample - loss: 11.4242 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11.4245 - accuracy: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4237 - accuracy: 0.0990\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 11.4240 - accuracy: 0.0950\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 11.4238 - accuracy: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e89b048b00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10)])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llipvR5wIl_t"
   },
   "source": [
    "Learn more about creating new layers and models from scratch with subclassing in the [Guide to writing layers and models from scratch](./custom_layers_and_models.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lu8cc3AJ0E2v"
   },
   "source": [
    "## Callbacks\n",
    "\n",
    "A callback is an object passed to a model to customize and extend its behavior\n",
    "during training. You can write your own custom callback, or use the built-in\n",
    "`tf.keras.callbacks` that include:\n",
    "\n",
    "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
    "  regular intervals.\n",
    "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
    "  rate.\n",
    "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
    "  performance has stopped improving.\n",
    "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
    "  [TensorBoard](https://tensorflow.org/tensorboard).\n",
    "\n",
    "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:29.473514Z",
     "start_time": "2020-03-16T13:37:29.367490Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rdYwzSYV0E2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "  32/1000 [..............................] - ETA: 0s - loss: 11.4655 - accuracy: 0.0625WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "ProfilerNotRunningError",
     "evalue": "Cannot stop profiling. No profiler is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProfilerNotRunningError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[1;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_successful_loop_finish\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m       \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[1;34m(self, step, mode, size)\u001b[0m\n\u001b[0;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[1;32m--> 788\u001b[1;33m               mode, 'end', step, batch_logs)\n\u001b[0m\u001b[0;32m    789\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    238\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m       \u001b[0mbatch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m       elif (not self._is_tracing and\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_log_trace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1746\u001b[0m             \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1747\u001b[1;33m             profiler_outdir=os.path.join(self._log_write_dir, 'train'))\n\u001b[0m\u001b[0;32m   1748\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tracing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mtrace_export\u001b[1;34m(name, step, profiler_outdir)\u001b[0m\n\u001b[0;32m   1239\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m     \u001b[0m_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofiler_outdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\profiler.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m       raise ProfilerNotRunningError(\n\u001b[1;32m---> 99\u001b[1;33m           'Cannot stop profiling. No profiler is running.')\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProfilerNotRunningError\u001b[0m: Cannot stop profiling. No profiler is running.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProfilerNotRunningError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-39669e871986>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      7\u001b[0m model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n\u001b[1;32m----> 8\u001b[1;33m           validation_data=(val_data, val_labels))\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[1;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m       \u001b[1;31m# End of all epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_end_hook\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;34m\"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_end\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    377\u001b[0m     \"\"\"\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_end\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1720\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1721\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_writers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_log_trace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'batch_%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m             \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1747\u001b[1;33m             profiler_outdir=os.path.join(self._log_write_dir, 'train'))\n\u001b[0m\u001b[0;32m   1748\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tracing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mtrace_export\u001b[1;34m(name, step, profiler_outdir)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m     \u001b[0m_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofiler_outdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m   \u001b[0mtrace_off\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\profiler.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_profiler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m       raise ProfilerNotRunningError(\n\u001b[1;32m---> 99\u001b[1;33m           'Cannot stop profiling. No profiler is running.')\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProfilerNotRunningError\u001b[0m: Cannot stop profiling. No profiler is running."
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./tb')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghhaGfX62abv"
   },
   "source": [
    "<a name='save_and_restore'></a>\n",
    "## Save and restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnl7K-aI0E2z"
   },
   "source": [
    "<a name=\"weights_only\"></a>\n",
    "### Save just the weights values\n",
    "\n",
    "Save and load the weights of a model using `tf.keras.Model.save_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:50.092353Z",
     "start_time": "2020-03-16T13:37:50.042351Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uQIANjB94fLB"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "layers.Dense(10)])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:50.914538Z",
     "start_time": "2020-03-16T13:37:50.801521Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4eoHJ-ny0E21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e8a3eddcc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u25Id3xe0E25"
   },
   "source": [
    "By default, this saves the model's weights in the\n",
    "[TensorFlow checkpoint](../checkpoint.ipynb) file format. Weights can\n",
    "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
    "implementation of Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:52.209069Z",
     "start_time": "2020-03-16T13:37:52.161060Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JSAYoFEd0E26"
   },
   "outputs": [],
   "source": [
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# Restore the model's state\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mje_yKL10E29"
   },
   "source": [
    "### Save just the model configuration\n",
    "\n",
    "A model's configuration can be saved—this serializes the model architecture\n",
    "without any weights. A saved configuration can recreate and initialize the same\n",
    "model, even without the code that defined the original model. Keras supports\n",
    "JSON and YAML serialization formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:55.525837Z",
     "start_time": "2020-03-16T13:37:55.522829Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EbET0oJTzGkq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:56.406034Z",
     "start_time": "2020-03-16T13:37:56.400034Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pX_badhH3yWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'batch_input_shape': [None, 32],\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'linear',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_18',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_3'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7CIa05r4yTb"
   },
   "source": [
    "Recreate the model (newly initialized) from the JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:59.323690Z",
     "start_time": "2020-03-16T13:37:59.310687Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J9UFv9k00E2_"
   },
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5NHtICh4uHK"
   },
   "source": [
    "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:00.315911Z",
     "start_time": "2020-03-16T13:38:00.309911Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aj24KB3Z36S4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      batch_input_shape: !!python/tuple\n",
      "      - null\n",
      "      - 32\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_17\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: linear\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_18\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_3\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O53Kerfl43v7"
   },
   "source": [
    "Recreate the model from the YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:04.514845Z",
     "start_time": "2020-03-16T13:38:04.495841Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "77yRuwg03_MG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPvOSSzM0E3B"
   },
   "source": [
    "Caution: Subclassed models are not serializable because their architecture is\n",
    "defined by the Python code in the body of the `call` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu8qMwld4-71"
   },
   "source": [
    "\n",
    "### Save the entire model in one file\n",
    "\n",
    "The entire model can be saved to a file that contains the weight values, the\n",
    "model's configuration, and even the optimizer's configuration. This allows you\n",
    "to checkpoint a model and resume training later—from the exact same\n",
    "state—without access to the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:12.482632Z",
     "start_time": "2020-03-16T13:38:11.367391Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "45oNY34Z0E3C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 219us/sample - loss: 12.2104 - accuracy: 0.0820\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 12.7022 - accuracy: 0.0920\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 13.7824 - accuracy: 0.1060\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 15.2384 - accuracy: 0.1010\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 16.7342 - accuracy: 0.0970\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create a simple model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='relu', input_shape=(32,)),\n",
    "  layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVBURDtI_I6"
   },
   "source": [
    "Learn more about saving and serialization for Keras models in the guide to [save and serialize models](./save_and_serialize.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMOWhDOB0E3E"
   },
   "source": [
    "<a name=\"eager_execution\"></a>\n",
    "## Eager execution\n",
    "\n",
    "[Eager execution](../eager.ipynb) is an imperative programming\n",
    "environment that evaluates operations immediately. This is not required for\n",
    "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
    "debugging.\n",
    "\n",
    "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
    "And while the `Sequential` and functional APIs can be used, eager execution\n",
    "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
    "that require you to write the forward pass as code (instead of the APIs that\n",
    "create models by assembling existing layers).\n",
    "\n",
    "See the [eager execution guide](../eager.ipynb) for\n",
    "examples of using Keras models with custom training loops and `tf.GradientTape`.\n",
    "You can also find a complete, short example [here](https://www.tensorflow.org/tutorials/quickstart/advanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wG3NVco5B5V"
   },
   "source": [
    "## Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PJZ6e9J5JHF"
   },
   "source": [
    "### Multiple GPUs\n",
    "\n",
    "`tf.keras` models can run on multiple GPUs using\n",
    "`tf.distribute.Strategy`. This API provides distributed\n",
    "training on multiple GPUs with almost no changes to existing code.\n",
    "\n",
    "Currently, `tf.distribute.MirroredStrategy` is the only supported\n",
    "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
    "synchronous training using all-reduce on a single machine. To use\n",
    "`distribute.Strategy`s , nest the optimizer instantiation and model construction and compilation in a `Strategy`'s `.scope()`, then\n",
    "train the model.\n",
    "\n",
    "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
    "single machine.\n",
    "\n",
    "First, define a model inside the distributed strategy scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:17.721815Z",
     "start_time": "2020-03-16T13:38:17.694810Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sbaRr7g-0E3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
    "  model.add(layers.Dense(1))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(0.2)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO9MiL6X0E3O"
   },
   "source": [
    "Next, train the model on data as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:31.479893Z",
     "start_time": "2020-03-16T13:38:29.220394Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BEwFq4PM0E3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32 steps\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.7049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e8a494a940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((1024, 10))\n",
    "y = np.random.randint(2, size=(1024, 1))\n",
    "x = tf.cast(x, tf.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6BXU5F90E3U"
   },
   "source": [
    "For more information, see the [full guide on Distributed Training in TensorFlow](../distributed_training.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "overview.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
